{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch.9 Data Aggregation and Group Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(12345)\n",
    "plt.rc('figure', figsize=(10, 6))\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "When True, IPython notebook will use html representation for pandas objects \n",
    "(if it is available). [default: True] [currently: True]\n",
    "'''\n",
    "pd.options.display.notebook_repr_html = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy mechanics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      data1     data2 key1 key2\n",
       "0 -0.204708  1.393406    a  one\n",
       "1  0.478943  0.092908    a  two\n",
       "2 -0.519439  0.281746    b  one\n",
       "3 -0.555730  0.769023    b  two\n",
       "4  1.965781  1.246435    a  one"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrame({'key1' : ['a', 'a', 'b', 'b', 'a'],\n",
    "                'key2' : ['one', 'two', 'one', 'two', 'one'],\n",
    "                'data1' : np.random.randn(5),\n",
    "                'data2' : np.random.randn(5)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.SeriesGroupBy object at 0x1156d3320>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df['data1'].groupby(df['key1'])\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key1\n",
       "a    0.746672\n",
       "b   -0.537585\n",
       "Name: data1, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#group the dataframe by its value in 'key1'\n",
    "grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key1  key2\n",
       "a     one     0.880536\n",
       "      two     0.478943\n",
       "b     one    -0.519439\n",
       "      two    -0.555730\n",
       "Name: data1, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = df['data1'].groupby([df['key1'], df['key2']]).mean()\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key2       one       two\n",
       "key1                    \n",
       "a     0.880536  0.478943\n",
       "b    -0.519439 -0.555730"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California  2005    0.478943\n",
       "            2006   -0.519439\n",
       "Ohio        2005   -0.380219\n",
       "            2006    1.965781\n",
       "Name: data1, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = np.array(['Ohio', 'California', 'California', 'Ohio', 'Ohio'])\n",
    "years = np.array([2005, 2005, 2006, 2005, 2006])\n",
    "df['data1'].groupby([states, years]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         data1     data2\n",
       "key1                    \n",
       "a     0.746672  0.910916\n",
       "b    -0.537585  0.525384"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('key1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              data1     data2\n",
       "key1 key2                    \n",
       "a    one   0.880536  1.319920\n",
       "     two   0.478943  0.092908\n",
       "b    one  -0.519439  0.281746\n",
       "     two  -0.555730  0.769023"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['key1', 'key2']).mean() \n",
    "#calculate the value of each categories divided by the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key1  key2\n",
       "a     one     2\n",
       "      two     1\n",
       "b     one     1\n",
       "      two     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['key1', 'key2']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "      data1     data2 key1 key2\n",
      "0 -0.204708  1.393406    a  one\n",
      "1  0.478943  0.092908    a  two\n",
      "4  1.965781  1.246435    a  one\n",
      "b\n",
      "      data1     data2 key1 key2\n",
      "2 -0.519439  0.281746    b  one\n",
      "3 -0.555730  0.769023    b  two\n"
     ]
    }
   ],
   "source": [
    "for name, group in df.groupby('key1'):\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('a', 'one'),       data1     data2 key1 key2\n",
      "0 -0.204708  1.393406    a  one\n",
      "4  1.965781  1.246435    a  one)\n",
      "(('a', 'two'),       data1     data2 key1 key2\n",
      "1  0.478943  0.092908    a  two)\n",
      "(('b', 'one'),       data1     data2 key1 key2\n",
      "2 -0.519439  0.281746    b  one)\n",
      "(('b', 'two'),      data1     data2 key1 key2\n",
      "3 -0.55573  0.769023    b  two)\n"
     ]
    }
   ],
   "source": [
    "#for (k1, k2), group in df.groupby(['key1', 'key2']):\n",
    "#    print((k1, k2))\n",
    "#    print(group)\n",
    "    \n",
    "for item in df.groupby(['key1', 'key2']):\n",
    "    print(item)\n",
    "#    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      data1     data2 key1 key2\n",
       "2 -0.519439  0.281746    b  one\n",
       "3 -0.555730  0.769023    b  two"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pieces = dict(list(df.groupby('key1')))\n",
    "pieces['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data1    float64\n",
       "data2    float64\n",
       "key1      object\n",
       "key2      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{dtype('float64'):       data1     data2\n",
       " 0 -0.204708  1.393406\n",
       " 1  0.478943  0.092908\n",
       " 2 -0.519439  0.281746\n",
       " 3 -0.555730  0.769023\n",
       " 4  1.965781  1.246435, dtype('O'):   key1 key2\n",
       " 0    a  one\n",
       " 1    a  two\n",
       " 2    b  one\n",
       " 3    b  two\n",
       " 4    a  one}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df.groupby(df.dtypes, axis=1)\n",
    "dict(list(grouped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a column or subset of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.DataFrameGroupBy object at 0x115ebabe0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('key1')['data1']\n",
    "df.groupby('key1')[['data2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.DataFrameGroupBy object at 0x115eba2b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['data1'].groupby(df['key1'])\n",
    "df[['data2']].groupby(df['key1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              data2\n",
       "key1 key2          \n",
       "a    one   1.319920\n",
       "     two   0.092908\n",
       "b    one   0.281746\n",
       "     two   0.769023"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['key1', 'key2'])[['data2']].mean()\n",
    "#df.groupby(['key1', 'key2']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.SeriesGroupBy object at 0x115eba8d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_grouped = df.groupby(['key1', 'key2'])['data2']\n",
    "s_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key1  key2\n",
       "a     one     1.319920\n",
       "      two     0.092908\n",
       "b     one     0.281746\n",
       "      two     0.769023\n",
       "Name: data2, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_grouped.mean() # same as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping with dicts and Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               a         b         c         d         e\n",
       "Joe     0.560145 -1.265934  0.119827 -1.063512  0.332883\n",
       "Steve  -2.359419 -0.199543 -1.541996 -0.970736 -1.307030\n",
       "Wes     0.286350       NaN       NaN  0.331286  1.349742\n",
       "Jim     0.069877  0.246674 -0.011862  1.004812  1.327195\n",
       "Travis -0.919262 -1.549106  0.022185  0.758363 -0.660524"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people = DataFrame(np.random.randn(5, 5),\n",
    "                   columns=['a', 'b', 'c', 'd', 'e'],\n",
    "                   index=['Joe', 'Steve', 'Wes', 'Jim', 'Travis'])\n",
    "people.loc[2:3, ['b', 'c']] = np.nan # Add a few NA values\n",
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'a': 'red', 'b': 'red', 'c': 'blue',\n",
    "           'd': 'blue', 'e': 'red', 'f' : 'orange'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            blue       red\n",
       "Joe    -0.943685 -0.372906\n",
       "Steve  -2.512731 -3.865992\n",
       "Wes     0.331286  1.636092\n",
       "Jim     0.992950  1.643745\n",
       "Travis  0.780548 -3.128892"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_column = people.groupby(mapping, axis=1)\n",
    "#'f' is for 'orange', so there is no data for the 'orange' label\n",
    "by_column.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a       red\n",
       "b       red\n",
       "c      blue\n",
       "d      blue\n",
       "e       red\n",
       "f    orange\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_series = Series(mapping)\n",
    "map_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               a         b         c         d         e\n",
       "Joe     0.560145 -1.265934  0.119827 -1.063512  0.332883\n",
       "Steve  -2.359419 -0.199543 -1.541996 -0.970736 -1.307030\n",
       "Wes     0.286350       NaN       NaN  0.331286  1.349742\n",
       "Jim     0.069877  0.246674 -0.011862  1.004812  1.327195\n",
       "Travis -0.919262 -1.549106  0.022185  0.758363 -0.660524"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        blue  red\n",
       "Joe        2    3\n",
       "Steve      2    3\n",
       "Wes        1    2\n",
       "Jim        2    3\n",
       "Travis     2    3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.groupby(map_series, axis=1).count() \n",
    "# return blue/red if the value exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping with functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          a         b         c         d         e\n",
       "3  0.916372 -1.019260  0.107966  0.272585  3.009820\n",
       "5 -2.359419 -0.199543 -1.541996 -0.970736 -1.307030\n",
       "6 -0.919262 -1.549106  0.022185  0.758363 -0.660524"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.groupby(len).sum()\n",
    "# to group the data by their length of index, then sum them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              a         b         c         d         e\n",
       "3 one  0.286350 -1.265934  0.119827 -1.063512  0.332883\n",
       "  two  0.069877  0.246674 -0.011862  1.004812  1.327195\n",
       "5 one -2.359419 -0.199543 -1.541996 -0.970736 -1.307030\n",
       "6 two -0.919262 -1.549106  0.022185  0.758363 -0.660524"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_list = ['one', 'one', 'one', 'two', 'two']\n",
    "people.groupby([len, key_list]).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping by index levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cty          US                            JP          \n",
       "tenor         1         3         5         1         3\n",
       "0      0.051316 -1.157719  0.816707  0.433610  1.010737\n",
       "1      1.824875 -0.997518  0.850591 -0.131578  0.912414\n",
       "2      0.188211  2.169461 -0.114928  2.003697  0.029610\n",
       "3      0.795253  0.118110 -0.748532  0.584970  0.152677"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = pd.MultiIndex.from_arrays([['US', 'US', 'US', 'JP', 'JP'],\n",
    "                                    [1, 3, 5, 1, 3]], names=['cty', 'tenor'])\n",
    "#Multi_Index_Method = pd.MultiIndex.from_arrays()\n",
    "hier_df = DataFrame(np.random.randn(4, 5), columns=columns)\n",
    "hier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cty  JP  US\n",
       "0     2   3\n",
       "1     2   3\n",
       "2     2   3\n",
       "3     2   3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hier_df.groupby(level='cty', axis=1).count()\n",
    "# to count the numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      data1     data2 key1 key2\n",
       "0 -0.204708  1.393406    a  one\n",
       "1  0.478943  0.092908    a  two\n",
       "2 -0.519439  0.281746    b  one\n",
       "3 -0.555730  0.769023    b  two\n",
       "4  1.965781  1.246435    a  one"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key1\n",
       "a    1.668413\n",
       "b   -0.523068\n",
       "Name: data1, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df.groupby('key1')\n",
    "grouped['data1'].quantile(0.9)\n",
    "# to calculate quantile, is equal to return the (min + (max-min) * quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         data1     data2\n",
       "key1                    \n",
       "a     2.170488  1.300498\n",
       "b     0.036292  0.487276"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def peak_to_peak(arr):\n",
    "    return arr.max() - arr.min()\n",
    "grouped.agg(peak_to_peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     data1                                                              \\\n",
       "     count      mean       std       min       25%       50%       75%   \n",
       "key1                                                                     \n",
       "a      3.0  0.746672  1.109736 -0.204708  0.137118  0.478943  1.222362   \n",
       "b      2.0 -0.537585  0.025662 -0.555730 -0.546657 -0.537585 -0.528512   \n",
       "\n",
       "               data2                                                    \\\n",
       "           max count      mean       std       min       25%       50%   \n",
       "key1                                                                     \n",
       "a     1.965781   3.0  0.910916  0.712217  0.092908  0.669671  1.246435   \n",
       "b    -0.519439   2.0  0.525384  0.344556  0.281746  0.403565  0.525384   \n",
       "\n",
       "                          \n",
       "           75%       max  \n",
       "key1                      \n",
       "a     1.319920  1.393406  \n",
       "b     0.647203  0.769023  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.describe() # a typical statistical summary of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column-wise and multiple function application\n",
    "This part has been clipped due to the lack of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returning aggregated data in \"unindexed\" form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tips.groupby(['sex', 'smoker'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group-wise operations and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      data1     data2 key1 key2\n",
       "0 -0.204708  1.393406    a  one\n",
       "1  0.478943  0.092908    a  two\n",
       "2 -0.519439  0.281746    b  one\n",
       "3 -0.555730  0.769023    b  two\n",
       "4  1.965781  1.246435    a  one"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "To add a column to a DataFrame containing group means for each index. \n",
    "One way to do this is to aggregate, then merge.\n",
    "'''\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      mean_data1  mean_data2\n",
       "key1                        \n",
       "a       0.746672    0.910916\n",
       "b      -0.537585    0.525384"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1_means = df.groupby('key1').mean().add_prefix('mean_')\n",
    "k1_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      data1     data2 key1 key2  mean_data1  mean_data2\n",
       "0 -0.204708  1.393406    a  one    0.746672    0.910916\n",
       "1  0.478943  0.092908    a  two    0.746672    0.910916\n",
       "4  1.965781  1.246435    a  one    0.746672    0.910916\n",
       "2 -0.519439  0.281746    b  one   -0.537585    0.525384\n",
       "3 -0.555730  0.769023    b  two   -0.537585    0.525384"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df, k1_means, left_on='key1', right_index=True)\n",
    "# it seems that the 'right_index=True' is a necessary sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            a         b         c         d         e\n",
       "one -0.024256 -1.407520  0.071006  0.008712  0.340700\n",
       "two -1.144771  0.023566 -0.776929  0.017038  0.010082"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = ['one', 'two', 'one', 'two', 'one']\n",
    "# odd and even index people\n",
    "people.groupby(key).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               a         b         c         d         e\n",
       "Joe    -0.024256 -1.407520  0.071006  0.008712  0.340700\n",
       "Steve  -1.144771  0.023566 -0.776929  0.017038  0.010082\n",
       "Wes    -0.024256 -1.407520  0.071006  0.008712  0.340700\n",
       "Jim    -1.144771  0.023566 -0.776929  0.017038  0.010082\n",
       "Travis -0.024256 -1.407520  0.071006  0.008712  0.340700"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.groupby(key).transform(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               a         b         c         d         e\n",
       "Joe     0.584401  0.141586  0.048821 -1.072225 -0.007817\n",
       "Steve  -1.214648 -0.223109 -0.765067 -0.987774 -1.317112\n",
       "Wes     0.310605       NaN       NaN  0.322574  1.009042\n",
       "Jim     1.214648  0.223109  0.765067  0.987774  1.317112\n",
       "Travis -0.895006 -0.141586 -0.048821  0.749651 -1.001225"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def demean(arr):\n",
    "    return arr - arr.mean()\n",
    "demeaned = people.groupby(key).transform(demean)\n",
    "demeaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       a             b             c    d             e\n",
       "one  0.0  1.110223e-16  6.938894e-18  0.0  7.401487e-17\n",
       "two  0.0  0.000000e+00  0.000000e+00  0.0  0.000000e+00"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demeaned.groupby(key).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply: General split-apply-combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top(df, n=5, column='tip_pct'):\n",
    "    return df.sort_index(by=column)[-n:]\n",
    "\n",
    "# to select the top five tip_pct(column name) values by group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppressing the group keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tips.groupby('smoker', group_keys=False).apply(top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile and bucket analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (-1.185, 0.509]\n",
       "1     (0.509, 2.204]\n",
       "2    (-1.185, 0.509]\n",
       "3    (-1.185, 0.509]\n",
       "4    (-1.185, 0.509]\n",
       "5     (0.509, 2.204]\n",
       "6    (-1.185, 0.509]\n",
       "7     (0.509, 2.204]\n",
       "8     (0.509, 2.204]\n",
       "9     (0.509, 2.204]\n",
       "Name: data1, dtype: category\n",
       "Categories (4, interval[float64]): [(-2.885, -1.185] < (-1.185, 0.509] < (0.509, 2.204] < (2.204, 3.898]]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = DataFrame({'data1': np.random.randn(1000),\n",
    "                   'data2': np.random.randn(1000)})\n",
    "\n",
    "factor = pd.cut(frame.data1, 4)\n",
    "'''\n",
    "pd.cut(x, bins, right=True, labels=None, retbins=False, \n",
    "precision=3, include_lowest=False)\n",
    "\n",
    "bins : int, sequence of scalars, or IntervalIndex\n",
    "    If `bins` is an int, it defines the number of equal-width bins in the\n",
    "    range of `x`. However, in this case, the range of `x` is extended\n",
    "    by .1% on each side to include the min or max values of `x`. If\n",
    "    `bins` is a sequence it defines the bin edges allowing for\n",
    "    non-uniform bin width. No extension of the range of `x` is done in\n",
    "    this case.\n",
    "    \n",
    "bins = 4, which means for each data, factor will save \n",
    "        the first 4 digits of the data.\n",
    "'''\n",
    "factor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  count       max      mean       min\n",
       "data1                                                \n",
       "(-3.201, -1.64]    44.0  1.562211 -0.054708 -1.614189\n",
       "(-1.64, -0.0853]  401.0  3.082067 -0.033824 -3.481593\n",
       "(-0.0853, 1.469]  490.0  3.189940 -0.034471 -2.939965\n",
       "(1.469, 3.024]     65.0  1.398385 -0.136144 -2.246992"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_stats(group):\n",
    "    return {'min': group.min(), 'max': group.max(),\n",
    "            'count': group.count(), 'mean': group.mean()}\n",
    "# 简易版的.describe() method\n",
    "grouped = frame.data2.groupby(factor)\n",
    "grouped.apply(get_stats).unstack()\n",
    "\n",
    "#ADAPT the output is not sorted in the book \n",
    "#while this is the case now (swap first two lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       count       max      mean       min\n",
       "data1                                     \n",
       "0      100.0  2.404580 -0.163764 -2.587681\n",
       "1      100.0  2.040657 -0.023332 -2.904543\n",
       "2      100.0  2.231810  0.142036 -2.403642\n",
       "3      100.0  2.138638 -0.115840 -2.794475\n",
       "4      100.0  2.267944 -0.024669 -3.255825\n",
       "5      100.0  3.521136 -0.035211 -2.133437\n",
       "6      100.0  2.478106 -0.022286 -2.098641\n",
       "7      100.0  2.246298  0.031404 -2.924827\n",
       "8      100.0  2.533112  0.154331 -3.398085\n",
       "9      100.0  2.943909  0.097091 -2.938085"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return quantile numbers\n",
    "grouping = pd.qcut(frame.data1, 10, labels=False)\n",
    "\n",
    "grouped = frame.data2.groupby(grouping)\n",
    "grouped.apply(get_stats).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Filling missing values with group-specific values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1    1.844281\n",
       "2         NaN\n",
       "3    0.447351\n",
       "4         NaN\n",
       "5    0.999861\n",
       "dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Series(np.random.randn(6))\n",
    "s[::2] = np.nan\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.097164\n",
       "1    1.844281\n",
       "2    1.097164\n",
       "3    0.447351\n",
       "4    1.097164\n",
       "5    0.999861\n",
       "dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.fillna(s.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ohio          0.880438\n",
       "New York     -1.400894\n",
       "Vermont            NaN\n",
       "Florida       0.730709\n",
       "Oregon        0.788423\n",
       "Nevada             NaN\n",
       "California    0.540007\n",
       "Idaho              NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = ['Ohio', 'New York', 'Vermont', 'Florida',\n",
    "          'Oregon', 'Nevada', 'California', 'Idaho']\n",
    "group_key = ['East'] * 4 + ['West'] * 4 \n",
    "    #这里应该存的是4个‘East’再加上4个‘West’\n",
    "data = Series(np.random.randn(8), index=states)\n",
    "data[['Vermont', 'Nevada', 'Idaho']] = np.nan\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "East    0.070084\n",
       "West    0.664215\n",
       "dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(group_key).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ohio          0.880438\n",
       "New York     -1.400894\n",
       "Vermont       0.070084\n",
       "Florida       0.730709\n",
       "Oregon        0.788423\n",
       "Nevada        0.664215\n",
       "California    0.540007\n",
       "Idaho         0.664215\n",
       "dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mean = lambda g: g.fillna(g.mean())\n",
    "data.groupby(group_key).apply(fill_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ohio          0.880438\n",
       "New York     -1.400894\n",
       "Vermont       0.500000\n",
       "Florida       0.730709\n",
       "Oregon        0.788423\n",
       "Nevada       -1.000000\n",
       "California    0.540007\n",
       "Idaho        -1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_values = {'East': 0.5, 'West': -1}\n",
    "fill_func = lambda g: g.fillna(fill_values[g.name])\n",
    "\n",
    "data.groupby(group_key).apply(fill_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Random sampling and permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hearts, Spades, Clubs, Diamonds\n",
    "suits = ['H', 'S', 'C', 'D']\n",
    "card_val = (list(range(1, 11)) + [10] * 3) * 4\n",
    "base_names = ['A'] + list(range(2, 11)) + ['J', 'K', 'Q'] #Cards Value\n",
    "#print(base_names)\n",
    "cards = []\n",
    "for suit in ['H', 'S', 'C', 'D']:\n",
    "    cards.extend(str(num) + suit for num in base_names)\n",
    "\n",
    "deck = Series(card_val, index=cards)\n",
    "\n",
    "# To generate a dataframe which stores the data for a entire set of cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AH      1\n",
       "2H      2\n",
       "3H      3\n",
       "4H      4\n",
       "5H      5\n",
       "6H      6\n",
       "7H      7\n",
       "8H      8\n",
       "9H      9\n",
       "10H    10\n",
       "JH     10\n",
       "KH     10\n",
       "QH     10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deck[:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2C     2\n",
       "JD    10\n",
       "AD     1\n",
       "KH    10\n",
       "KS    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def draw(deck, n=5):\n",
    "    return deck.take(np.random.permutation(len(deck))[:n])\n",
    "draw(deck)\n",
    "# here deck is a dataframe/series, so series.take\n",
    "#np.random.permutation: \n",
    "#  - Randomly permute a sequence, or return a permuted range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C  10C    10\n",
       "   2C      2\n",
       "D  7D      7\n",
       "   6D      6\n",
       "H  AH      1\n",
       "   7H      7\n",
       "S  QS     10\n",
       "   6S      6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_suit = lambda card: card[-1] # last letter is suit\n",
    "deck.groupby(get_suit).apply(draw, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KC    10\n",
       "6C     6\n",
       "3D     3\n",
       "2D     2\n",
       "4H     4\n",
       "6H     6\n",
       "7S     7\n",
       "9S     9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternatively\n",
    "deck.groupby(get_suit, group_keys=False).apply(draw, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Group weighted average and correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame({'category': ['a', 'a', 'a', 'a', 'b', 'b', 'b', 'b'],\n",
    "                'data': np.random.randn(8),\n",
    "                'weights': np.random.rand(8)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('category')\n",
    "get_wavg = lambda g: np.average(g['data'], weights=g['weights'])\n",
    "grouped.apply(get_wavg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_px = pd.read_csv('ch09/stock_px.csv', parse_dates=True, index_col=0)\n",
    "close_px.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_px[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = close_px.pct_change().dropna()\n",
    "spx_corr = lambda x: x.corrwith(x['SPX'])\n",
    "by_year = rets.groupby(lambda x: x.year)\n",
    "by_year.apply(spx_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annual correlation of Apple with Microsoft\n",
    "by_year.apply(lambda g: g['AAPL'].corr(g['MSFT']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Group-wise linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "def regress(data, yvar, xvars):\n",
    "    Y = data[yvar]\n",
    "    X = data[xvars]\n",
    "    X['intercept'] = 1.\n",
    "    result = sm.OLS(Y, X).fit()\n",
    "    return result.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_year.apply(regress, 'AAPL', ['SPX'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot tables and Cross-tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.pivot_table(index=['sex', 'smoker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.pivot_table(['tip_pct', 'size'], index=['sex', 'day'],\n",
    "                 columns='smoker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.pivot_table(['tip_pct', 'size'], index=['sex', 'day'],\n",
    "                 columns='smoker', margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.pivot_table('tip_pct', index=['sex', 'smoker'], columns='day',\n",
    "                 aggfunc=len, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.pivot_table('size', index=['time', 'sex', 'smoker'],\n",
    "                 columns='day', aggfunc='sum', fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-tabulations: crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from StringIO import StringIO\n",
    "data = \"\"\"\\\n",
    "Sample    Gender    Handedness\n",
    "1    Female    Right-handed\n",
    "2    Male    Left-handed\n",
    "3    Female    Right-handed\n",
    "4    Male    Right-handed\n",
    "5    Male    Left-handed\n",
    "6    Male    Right-handed\n",
    "7    Female    Right-handed\n",
    "8    Female    Left-handed\n",
    "9    Male    Right-handed\n",
    "10    Female    Right-handed\"\"\"\n",
    "data = pd.read_table(StringIO(data), sep='\\s+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data.Gender, data.Handedness, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([tips.time, tips.day], tips.smoker, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: 2012 Federal Election Commission Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fec = pd.read_csv('ch09/P00000001-ALL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fec.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fec.ix[123456]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cands = fec.cand_nm.unique()\n",
    "unique_cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cands[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parties = {'Bachmann, Michelle': 'Republican',\n",
    "           'Cain, Herman': 'Republican',\n",
    "           'Gingrich, Newt': 'Republican',\n",
    "           'Huntsman, Jon': 'Republican',\n",
    "           'Johnson, Gary Earl': 'Republican',\n",
    "           'McCotter, Thaddeus G': 'Republican',\n",
    "           'Obama, Barack': 'Democrat',\n",
    "           'Paul, Ron': 'Republican',\n",
    "           'Pawlenty, Timothy': 'Republican',\n",
    "           'Perry, Rick': 'Republican',\n",
    "           \"Roemer, Charles E. 'Buddy' III\": 'Republican',\n",
    "           'Romney, Mitt': 'Republican',\n",
    "           'Santorum, Rick': 'Republican'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fec.cand_nm[123456:123461]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fec.cand_nm[123456:123461].map(parties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add it as a column\n",
    "fec['party'] = fec.cand_nm.map(parties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fec['party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fec.contb_receipt_amt > 0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fec = fec[fec.contb_receipt_amt > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fec_mrbo = fec[fec.cand_nm.isin(['Obama, Barack', 'Romney, Mitt'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Donation statistics by occupation and employer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fec.contbr_occupation.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_mapping = {\n",
    "   'INFORMATION REQUESTED PER BEST EFFORTS' : 'NOT PROVIDED',\n",
    "   'INFORMATION REQUESTED' : 'NOT PROVIDED',\n",
    "   'INFORMATION REQUESTED (BEST EFFORTS)' : 'NOT PROVIDED',\n",
    "   'C.E.O.': 'CEO'\n",
    "}\n",
    "\n",
    "# If no mapping provided, return x\n",
    "f = lambda x: occ_mapping.get(x, x)\n",
    "fec.contbr_occupation = fec.contbr_occupation.map(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_mapping = {\n",
    "   'INFORMATION REQUESTED PER BEST EFFORTS' : 'NOT PROVIDED',\n",
    "   'INFORMATION REQUESTED' : 'NOT PROVIDED',\n",
    "   'SELF' : 'SELF-EMPLOYED',\n",
    "   'SELF EMPLOYED' : 'SELF-EMPLOYED',\n",
    "}\n",
    "\n",
    "# If no mapping provided, return x\n",
    "f = lambda x: emp_mapping.get(x, x)\n",
    "fec.contbr_employer = fec.contbr_employer.map(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_occupation = fec.pivot_table('contb_receipt_amt',\n",
    "                                index='contbr_occupation',\n",
    "                                columns='party', aggfunc='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_2mm = by_occupation[by_occupation.sum(1) > 2000000]\n",
    "over_2mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_2mm.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_amounts(group, key, n=5):\n",
    "    totals = group.groupby(key)['contb_receipt_amt'].sum()\n",
    "\n",
    "    # Order totals by key in descending order\n",
    "    return totals.order(ascending=False)[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = fec_mrbo.groupby('cand_nm')\n",
    "grouped.apply(get_top_amounts, 'contbr_occupation', n=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.apply(get_top_amounts, 'contbr_employer', n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucketing donation amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.array([0, 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000])\n",
    "labels = pd.cut(fec_mrbo.contb_receipt_amt, bins)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = fec_mrbo.groupby(['cand_nm', labels])\n",
    "grouped.size().unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_sums = grouped.contb_receipt_amt.sum().unstack(0)\n",
    "bucket_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_sums = bucket_sums.div(bucket_sums.sum(axis=1), axis=0)\n",
    "normed_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_sums[:-2].plot(kind='barh', stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Donation statistics by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = fec_mrbo.groupby(['cand_nm', 'contbr_st'])\n",
    "totals = grouped.contb_receipt_amt.sum().unstack(0).fillna(0)\n",
    "totals = totals[totals.sum(1) > 100000]\n",
    "totals[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = totals.div(totals.sum(1), axis=0)\n",
    "percent[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
